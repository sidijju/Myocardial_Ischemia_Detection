# -*- coding: utf-8 -*-
"""Data_Chunking.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VTJOStFSJb-kFfuSYAmsr1O1SzKgSbdA

# Preprocessing

In this notebook, we will process one sample of ECG data from the 2003 Physionet/Computers in Cardiology Challenge. The dataset, otherwise known as the Long-Term ST Database, contains 86 ECG recordings taken from 21 to 24 hours at 250 Hz, of 80 human subjects. The samples were chosen to exhibit a variety of events of ST segment changes, including ischemic ST episodes, axis-related non-ischemic ST episodes, episodes of slow ST level drift, and episodes containing mixtures of these phenomena.

First, we will import any required modules.
"""

#from google.colab import files
#import matplotlib.pyplot as plt
import sys
sys.path.insert(0, '../../../../../anaconda3/lib/python3.6/site-packages')
#sys.path.insert(0, '../../../../anaconda3/lib/python3.6/site-packages')
import numpy as np
import math


import os
import pandas as pd
import random
from sklearn import metrics
#!pip install peakutils
#import peakutils
#from sklearn.utils import shuffle
#import tensorflow as tf
from scipy.interpolate import *
from scipy.signal import *
import wfdb

#tf.enable_eager_execution()




#rtst, 2077500, 2250152
'''Labels: 
0 - Ischemic (Episode) - ST; 
1 - Heart-Rate Related (Episode) - RTST; 
2 - Normal;
3 - Conduction Change (shift) - SCCST; 
4 - Axis Shift (shift) - SST;
'''
#signal = ...
#columns = ...

FILENAME = sys.argv[1]
columns = pd.DataFrame.from_csv(FILENAME+".csv")

normalEndIndex = columns['1'].iloc[0] - 1300
normaldf = pd.DataFrame({'0': ['normal'], '1':[0], '2':[normalEndIndex]})
columns = columns.append(normaldf)

labelDict = {"st":0, "rtst":1, "sccst":2, "sst":3, "normal":4}
numSecondsPerChunk = 5
deltaFreq = 5
signals, fields = wfdb.rdsamp(FILENAME)
signals = signals[:, 0]
freq = fields['fs']

lengthOfChunk = numSecondsPerChunk * freq
data = pd.DataFrame({"Signal": [], "Label": []})



for index, row in columns.iterrows():
	label = row[0]
	begRange = row[1]
	endRange = row[2]
	for j in range(begRange, endRange, lengthOfChunk):
		x = np.array([signals[y] for y in range(j, j+lengthOfChunk)])
		if len(x) == lengthOfChunk:
			x = x.reshape(len(x)//deltaFreq,deltaFreq).mean(1).flatten()
			df2 = pd.DataFrame({"Signal" : [x], "Label" : [label]})
			data = data.append(df2)
	#print(splicedData)
	#chunkedSignal =  [signals[list(range(j,j+lengthOfChunk))] #[list(range(j,j+lengthOfChunk))]
data = data.reset_index(drop=True)
data.to_pickle("./"+FILENAME+ ".xz")
#print(data)
'''data1, data2, data3, data4, data5, data6, data7, data8, data9, data10 = np.array_split(data, 10)
dataloop = [data1, data2, data3, data4, data5, data6, data7, data8, data9, data10]
for i in range(len(dataloop)):
	dataloop[i].to_pickle("./"+FILENAME+ "_" + str(i) +".xz")'''

#print()
#print("done", FILENAME)

#Checks to make sure data is good
'''print(len(data.loc[data['Label'] == 'normal']))
print(len(data.loc[data['Label'] == 'rtst']))

newx = 0
for i in data['Signal']:
	if len(i)!=int(lengthOfChunk/deltaFreq):
		print(len(i))
		newx+=1
print("nx", newx)'''